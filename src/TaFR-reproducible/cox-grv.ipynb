{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-01T17:50:55.884808Z",
     "start_time": "2025-02-01T17:50:40.767939Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "def train_and_generate_grv_with_vitality(\n",
    "    item_hour_log_csv,\n",
    "    output_dir=\"./cox_output\",\n",
    "    T_obs=12,\n",
    "    T_pred=168,\n",
    "    min_obs_hours=1,\n",
    "    beta_d=-3.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Similar to the earlier cox training script, but we incorporate a \n",
    "    'vitality' approach for labeling the event time. \n",
    "    We'll do:\n",
    "      1) For each item, sort by hour_offset. \n",
    "      2) Build cumulative vitality. \n",
    "      3) The first hour >= T_i0+T_obs in which cumulativeVitality < beta_d => \"death\" hour. \n",
    "         If none, censored at T_i0+T_obs+T_pred.\n",
    "\n",
    "    If an item doesn't appear at certain hours (meaning no row), we treat vitality=0 that hour.\n",
    "    We'll store the item-level (duration, event) and train Cox. Then produce cox_survival.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df = pd.read_csv(item_hour_log_csv)\n",
    "    required = [\"item_id\",\"hour_offset\",\"exposure\",\"vitality\"]\n",
    "    for c in required:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Column '{c}' not found. Need vitality from Script A2.\")\n",
    "    df.sort_values([\"item_id\",\"hour_offset\"], inplace=True)\n",
    "\n",
    "    items = []\n",
    "    item_groups = df.groupby(\"item_id\", sort=False)\n",
    "\n",
    "    for it_id, group in item_groups:\n",
    "        group = group.sort_values(\"hour_offset\")\n",
    "        T_i0 = group[\"hour_offset\"].min()\n",
    "        obs_end = T_i0+T_obs\n",
    "        pred_end = obs_end+T_pred\n",
    "\n",
    "        # observation window\n",
    "        obs_df = group[(group[\"hour_offset\"]>=T_i0)&(group[\"hour_offset\"]<obs_end)]\n",
    "        # if insufficient hours => skip\n",
    "        if obs_df[\"hour_offset\"].nunique() < min_obs_hours:\n",
    "            continue\n",
    "\n",
    "        # Summation of 'exposure' or 'vitality' in obs\n",
    "        sum_exposure_obs = obs_df[\"exposure\"].sum()  # example feature\n",
    "        # for Cox, we keep \"sum_exposure_obs\" or do more advanced\n",
    "\n",
    "        # We'll look hour by hour in [obs_end, pred_end) to see if cummulativeVital < beta_d\n",
    "        # Actually we must compute cumulative vitality from T_i0 up to each hour offset.\n",
    "        # So let's build an array from T_i0 => pred_end-1\n",
    "        full_offsets = np.arange(T_i0, pred_end)\n",
    "        # We'll map them to vitality or 0 if no row\n",
    "        group_indexed = group.set_index(\"hour_offset\")\n",
    "        cume_val = 0.0\n",
    "        event_time = pred_end\n",
    "        event_flag = 0\n",
    "\n",
    "        for h in full_offsets:\n",
    "            if h in group_indexed.index:\n",
    "                vit = group_indexed.loc[h, \"vitality\"]\n",
    "                # if there's multiple rows, sum them, but typically there's 1\n",
    "                if isinstance(vit, pd.Series):\n",
    "                    vit = vit.sum()\n",
    "            else:\n",
    "                vit = 0.0  # no row => vitality=0\n",
    "            cume_val += vit\n",
    "            # only check if h >= obs_end\n",
    "            if h >= obs_end:\n",
    "                if cume_val < beta_d:\n",
    "                    event_time = h\n",
    "                    event_flag=1\n",
    "                    break\n",
    "        \n",
    "        duration = event_time - T_i0\n",
    "        items.append({\n",
    "            \"item_id\":it_id,\n",
    "            \"sum_exposure_obs\":sum_exposure_obs,\n",
    "            \"duration\": duration,\n",
    "            \"event\": event_flag,\n",
    "            \"T_i0\": T_i0\n",
    "        })\n",
    "\n",
    "    cox_df = pd.DataFrame(items)\n",
    "    if cox_df.empty:\n",
    "        print(\"No items. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Fit Cox\n",
    "    from lifelines import CoxPHFitter\n",
    "    cph = CoxPHFitter()\n",
    "    try:\n",
    "        cph.fit(\n",
    "            cox_df[[\"duration\",\"event\",\"sum_exposure_obs\",\"item_id\",\"T_i0\"]],\n",
    "            duration_col=\"duration\",\n",
    "            event_col=\"event\",\n",
    "            show_progress=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return\n",
    "\n",
    "    cox_df_out = os.path.join(output_dir, \"cox_data.csv\")\n",
    "    cox_df.to_csv(cox_df_out, index=False)\n",
    "    print(f\"[INFO] Saved cox_data.csv => {cox_df_out}\")\n",
    "\n",
    "    # cph summary\n",
    "    with open(os.path.join(output_dir,\"cox_model_summary.txt\"), \"w\") as f:\n",
    "        f.write(str(cph.summary))\n",
    "\n",
    "    # Build survival => cox_survival.csv\n",
    "    hour_points = list(range(T_obs+1, T_obs+T_pred+1))\n",
    "    item_features = {}\n",
    "    for row in cox_df.itertuples(index=False):\n",
    "        item_features[row.item_id] = {\n",
    "            \"sum_exposure_obs\": row.sum_exposure_obs,\n",
    "            \"T_i0\": row.T_i0\n",
    "        }\n",
    "    grv_rows = []\n",
    "\n",
    "    for it_id, feats in item_features.items():\n",
    "        row_dict = {\n",
    "            \"sum_exposure_obs\": feats[\"sum_exposure_obs\"],\n",
    "            \"duration\":0,\n",
    "            \"event\":0,\n",
    "            \"item_id\": it_id,\n",
    "            \"T_i0\": feats[\"T_i0\"]\n",
    "        }\n",
    "        df_item = pd.DataFrame([row_dict])\n",
    "        surv_fn = cph.predict_survival_function(df_item, times=hour_points)\n",
    "        # shape (#times, #rows=1)\n",
    "        arr = surv_fn.iloc[:,0].tolist()\n",
    "        out = {\"item_id\":it_id}\n",
    "        for i, t_val in enumerate(hour_points):\n",
    "            out[f\"GRV_t{t_val}\"] = arr[i]\n",
    "        grv_rows.append(out)\n",
    "    grv_df = pd.DataFrame(grv_rows)\n",
    "    surv_out = os.path.join(output_dir,\"cox_survival.csv\")\n",
    "    grv_df.to_csv(surv_out,index=False)\n",
    "    print(f\"[INFO] Wrote survival => {surv_out}\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    item_hour_log_csv = \"./output/ItemHourLog.csv\"\n",
    "    train_and_generate_grv_with_vitality(\n",
    "        item_hour_log_csv=item_hour_log_csv,\n",
    "        output_dir=\"./cox_output\",\n",
    "        T_obs=12,\n",
    "        T_pred=168,\n",
    "        min_obs_hours=1,\n",
    "        beta_d=-3.0\n",
    "    )\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: norm_delta = 9.29e-01, step_size = 0.9500, log_lik = -6363.85370, newton_decrement = 3.00e+02, seconds_since_start = 0.0\n",
      "Iteration 2: norm_delta = 5.74e-01, step_size = 0.9500, log_lik = -6052.11557, newton_decrement = 2.65e+01, seconds_since_start = 0.0\n",
      "Iteration 3: norm_delta = 1.28e+00, step_size = 0.9500, log_lik = -6017.60925, newton_decrement = 2.62e+01, seconds_since_start = 0.0\n",
      "Iteration 4: norm_delta = 2.05e+00, step_size = 0.9310, log_lik = -5983.49713, newton_decrement = 2.07e+01, seconds_since_start = 0.0\n",
      "Iteration 5: norm_delta = 2.22e+00, step_size = 0.9124, log_lik = -5958.10495, newton_decrement = 9.66e+00, seconds_since_start = 0.0\n",
      "Iteration 6: norm_delta = 1.42e+00, step_size = 0.8941, log_lik = -5947.06383, newton_decrement = 2.15e+00, seconds_since_start = 0.0\n",
      "Iteration 7: norm_delta = 4.70e-01, step_size = 0.8762, log_lik = -5944.79223, newton_decrement = 1.74e-01, seconds_since_start = 0.0\n",
      "Iteration 8: norm_delta = 2.53e-02, step_size = 1.0000, log_lik = -5944.61269, newton_decrement = 4.55e-04, seconds_since_start = 0.0\n",
      "Iteration 9: norm_delta = 6.61e-05, step_size = 1.0000, log_lik = -5944.61224, newton_decrement = 3.09e-09, seconds_since_start = 0.0\n",
      "Convergence success after 9 iterations.\n",
      "[INFO] Saved cox_data.csv => ./cox_output/cox_data.csv\n",
      "[INFO] Wrote survival => ./cox_output/cox_survival.csv\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
